{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <a href=\"MLSD-04-FeatureEngineering-A.ipynb\" target=\"_self\">Feature Engineering A</a> | <a href=\"./\">Content Page</a> | <a href=\"MLSD-04-FeatureEngineering-Ex-1.ipynb\">Feature Engineering Exercise</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>FEATURE ENGINEERING B</center>\n",
    "\n",
    "<center><b>Copyright &copy 2023 by DR DANNY POO</b><br> e:dannypoo@nus.edu.sg<br> w:drdannypoo.com</center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "- Categorical features.\n",
    "- Text features.\n",
    "- Imputation of missing data.\n",
    "- Feature pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "data = [\n",
    "    {'price': 850000, 'rooms': 4, 'neighborhood': 'Changi'},\n",
    "    {'price': 720000, 'rooms': 3, 'neighborhood': 'Kembangan'},\n",
    "    {'price': 650000, 'rooms': 3, 'neighborhood': 'Pasir Panjang'},\n",
    "    {'price': 950000, 'rooms': 4, 'neighborhood': 'Woodlands'},\n",
    "    {'price': 830000, 'rooms': 4, 'neighborhood': 'Jurong'},\n",
    "    {'price': 680000, 'rooms': 2, 'neighborhood': 'Marine Parade'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- It would be wrong to encode as {'Changi': 1, 'Kembangan': 2, 'Pasir Panjang': 3, 'Woodlands': 4, 'Jurong': 5, 'Marine Parade': 6};\n",
    "- Instead use one-hot encoding which will create extra columns indicating the presence or absence of a category with a value of 1 or 0 respectively.\n",
    "- When data comes as a list of dictionaries (as above), can use Scikit-Learn's DictVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1,      0,      0,      0,      0,      0, 850000,      4],\n",
       "       [     0,      0,      1,      0,      0,      0, 720000,      3],\n",
       "       [     0,      0,      0,      0,      1,      0, 650000,      3],\n",
       "       [     0,      0,      0,      0,      0,      1, 950000,      4],\n",
       "       [     0,      1,      0,      0,      0,      0, 830000,      4],\n",
       "       [     0,      0,      0,      1,      0,      0, 680000,      2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode using DictVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer(sparse=False, dtype=int)\n",
    "vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- The 'neighborhood' column has been expanded into 6 separate columns, representing the 6 neighborhood labels, and that each row has a 1 in the column associated with its neighborhood.\n",
    "- We can now fit the Scikit-Learn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neighborhood=Changi', 'neighborhood=Jurong',\n",
       "       'neighborhood=Kembangan', 'neighborhood=Marine Parade',\n",
       "       'neighborhood=Pasir Panjang', 'neighborhood=Woodlands', 'price',\n",
       "       'rooms'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the feature names\n",
    "vec.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Disadvantage: if your category has many possible values, this can greatly increase the size of your dataset. \n",
    "- Since encoded data contains mostly zeros, use the spare output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x8 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 18 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set spare=True to reduce the size of matrix\n",
    "vec = DictVectorizer(sparse=True, dtype=int)\n",
    "vec.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- <b>sklearn.preprocessing.OneHotEncoder</b> and <b>sklearn.feature_extraction.FeatureHasher</b> are two additional tools that Scikit-Learn includes to support this type of encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "data = ['The Dark Knight',\n",
    "        'Batman and Robin',\n",
    "        'Man of Steel',\n",
    "        'Superman',\n",
    "        'Rise of the Dark Knight',\n",
    "        'Monty Python',\n",
    "        'The incredibles',\n",
    "        'The Golden Goose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<8x16 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 22 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a column representing each of the words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(data)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>batman</th>\n",
       "      <th>dark</th>\n",
       "      <th>golden</th>\n",
       "      <th>goose</th>\n",
       "      <th>incredibles</th>\n",
       "      <th>knight</th>\n",
       "      <th>man</th>\n",
       "      <th>monty</th>\n",
       "      <th>of</th>\n",
       "      <th>python</th>\n",
       "      <th>rise</th>\n",
       "      <th>robin</th>\n",
       "      <th>steel</th>\n",
       "      <th>superman</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  batman  dark  golden  goose  incredibles  knight  man  monty  of  \\\n",
       "0    0       0     1       0      0            0       1    0      0   0   \n",
       "1    1       1     0       0      0            0       0    0      0   0   \n",
       "2    0       0     0       0      0            0       0    1      0   1   \n",
       "3    0       0     0       0      0            0       0    0      0   0   \n",
       "4    0       0     1       0      0            0       1    0      0   1   \n",
       "5    0       0     0       0      0            0       0    0      1   0   \n",
       "6    0       0     0       0      0            1       0    0      0   0   \n",
       "7    0       0     0       1      1            0       0    0      0   0   \n",
       "\n",
       "   python  rise  robin  steel  superman  the  \n",
       "0       0     0      0      0         0    1  \n",
       "1       0     0      1      0         0    0  \n",
       "2       0     0      0      1         0    0  \n",
       "3       0     0      0      0         1    0  \n",
       "4       0     1      0      0         0    1  \n",
       "5       1     0      0      0         0    0  \n",
       "6       0     0      0      0         0    1  \n",
       "7       0     0      0      0         0    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display data in a dataframe\n",
    "pd.DataFrame(X.toarray(), columns=vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Issue: The raw word counts lead to features which put too much weight on words that appear very frequently, and this can be sub-optimal in some classification algorithms. \n",
    "- Solution: Use <b>term frequency-inverse document frequency (TF–IDF)</b> which weights the word counts by a measure of how often they appear in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>batman</th>\n",
       "      <th>dark</th>\n",
       "      <th>golden</th>\n",
       "      <th>goose</th>\n",
       "      <th>incredibles</th>\n",
       "      <th>knight</th>\n",
       "      <th>man</th>\n",
       "      <th>monty</th>\n",
       "      <th>of</th>\n",
       "      <th>python</th>\n",
       "      <th>rise</th>\n",
       "      <th>robin</th>\n",
       "      <th>steel</th>\n",
       "      <th>superman</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.623489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.623489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.608313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533823</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.338487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.844534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.645221</td>\n",
       "      <td>0.645221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       and   batman      dark    golden     goose  incredibles    knight  \\\n",
       "0  0.00000  0.00000  0.623489  0.000000  0.000000     0.000000  0.623489   \n",
       "1  0.57735  0.57735  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "2  0.00000  0.00000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "3  0.00000  0.00000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "4  0.00000  0.00000  0.447385  0.000000  0.000000     0.000000  0.447385   \n",
       "5  0.00000  0.00000  0.000000  0.000000  0.000000     0.000000  0.000000   \n",
       "6  0.00000  0.00000  0.000000  0.000000  0.000000     0.844534  0.000000   \n",
       "7  0.00000  0.00000  0.000000  0.645221  0.645221     0.000000  0.000000   \n",
       "\n",
       "        man     monty        of    python      rise    robin     steel  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.57735  0.000000   \n",
       "2  0.608313  0.000000  0.509814  0.000000  0.000000  0.00000  0.608313   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "4  0.000000  0.000000  0.447385  0.000000  0.533823  0.00000  0.000000   \n",
       "5  0.000000  0.707107  0.000000  0.707107  0.000000  0.00000  0.000000   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "7  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "\n",
       "   superman       the  \n",
       "0       0.0  0.471725  \n",
       "1       0.0  0.000000  \n",
       "2       0.0  0.000000  \n",
       "3       1.0  0.000000  \n",
       "4       0.0  0.338487  \n",
       "5       0.0  0.000000  \n",
       "6       0.0  0.535502  \n",
       "7       0.0  0.409122  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying term frequency-inverse document frequency (TF–IDF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "X = vec.fit_transform(data)\n",
    "pd.DataFrame(X.toarray(), columns=vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation of Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "X = np.array([[ nan, 0,   3  ],\n",
    "              [ 3,   7,   9  ],\n",
    "              [ 3,   5,   2  ],\n",
    "              [ 4,   nan, 6  ],\n",
    "              [ 8,   8,   1  ]])\n",
    "y = np.array([14, 16, -1,  8, -5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- Need to first replace such missing data with some appropriate fill value. \n",
    "- This is known as imputation of missing values, and strategies range from simple (e.g., replacing missing values with the <b>mean of the column</b>) to sophisticated (e.g., using matrix completion or a robust model to handle such data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.5 0.  3. ]\n",
      " [3.  7.  9. ]\n",
      " [3.  5.  2. ]\n",
      " [4.  5.  6. ]\n",
      " [8.  8.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "# Use Scikit-Learn SimpleImputer class\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputa = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "imputa.fit(X[:, 0:3]) # identifies the missing values and computes the mean of such feature where a missing value is present.\n",
    "\n",
    "# Replace the missing value using transform method\n",
    "X1 = imputa.transform(X[:, 0:3])\n",
    "print(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- The two missing values have been replaced with the mean of the remaining values in the column. \n",
    "- This imputed data can then be fed directly into, for example, a LinearRegression estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.14869292, 14.3784627 , -1.15539732, 10.96606197, -5.33782027])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression().fit(X1, y)\n",
    "model.predict(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Pipelines\n",
    "- When there are multiple steps involved, can use feature processing pipeline:\n",
    "1. Impute missing values using the mean\n",
    "2. Fit a linear regression\n",
    "\n",
    "- Can use Scikit-Learn Pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Scikit-Learn Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(SimpleImputer(strategy='mean'),\n",
    "                      LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 16 -1  8 -5]\n",
      "[13.14869292 14.3784627  -1.15539732 10.96606197 -5.33782027]\n"
     ]
    }
   ],
   "source": [
    "# Fit a model\n",
    "model.fit(X, y)  # X with missing values, from above\n",
    "print(y)\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "- All the steps of the model are applied automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <a href=\"MLSD-04-FeatureEngineering-A.ipynb\" target=\"_self\">Feature Engineering A</a> | <a href=\"./\">Content Page</a> | <a href=\"MLSD-04-FeatureEngineering-Ex-1.ipynb\">Feature Engineering Exercise</a>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
